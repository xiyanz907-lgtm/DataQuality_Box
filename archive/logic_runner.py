import polars as pl
import importlib
import logging
import traceback
import os
import pendulum
from datetime import datetime, timedelta
from services.datasource import get_datasource
from services.config import get_table_config

logger = logging.getLogger("airflow.task")

class LogicRunner:
    def __init__(self, cactus_conn_id, ngen_conn_id):
        """åˆå§‹åŒ–æ•°æ®æºã€‚

        Args:
            cactus_conn_id: KPI (cactus) æ•°æ®åº“çš„ Airflow è¿æ¥ IDã€‚
            ngen_conn_id: nGen æ•°æ®åº“çš„ Airflow è¿æ¥ IDã€‚
        """
        # æ•°æ®æºå·¥å‚ï¼šç›®å‰ä»… mysqlï¼Œåç»­å¯æ‰©å±•
        self.ds_kpi = get_datasource("mysql", cactus_conn_id)
        self.ds_ngen = get_datasource("mysql", ngen_conn_id)

    def _get_local_time_range_sql(self, date_filter_utc, col_name="On_Chasis_Datetime"):
        """
        æ ¹æ® UTC æ—¥æœŸç”Ÿæˆå¯¹åº” Local Time çš„ SQL è¿‡æ»¤æ¡ä»¶ã€‚
        è§£å†³ nGen (Local Time) ä¸ Cactus (UTC) çš„æ—¶åŒºå¯¹é½é—®é¢˜ã€‚
        """
        try:
            site_tz = os.getenv("SITE_TIMEZONE", "UTC")
            # æ„é€  UTC æ—¶é—´èŒƒå›´
            utc_start = pendulum.from_format(date_filter_utc, "YYYY-MM-DD", tz="UTC").start_of("day")
            utc_end = pendulum.from_format(date_filter_utc, "YYYY-MM-DD", tz="UTC").end_of("day")
            
            # è½¬æ¢ä¸º Site Local Time
            local_start = utc_start.in_timezone(site_tz)
            local_end = utc_end.in_timezone(site_tz)
            
            # æ ¼å¼åŒ–ä¸º SQL å­—ç¬¦ä¸² (å‡è®¾ nGen å­˜å‚¨æ ¼å¼å¯è¢« STR_TO_DATE è§£æ)
            fmt = "%Y-%m-%d %H:%M:%S"
            s_str = local_start.strftime(fmt)
            e_str = local_end.strftime(fmt)
            
            # æ„é€  BETWEEN å­å¥
            # nGen å­—æ®µé€šå¸¸æ˜¯å­—ç¬¦ä¸² 'DD/MM/YYYY HH:MM:SS'
            return f"STR_TO_DATE({col_name}, '%d/%m/%Y %H:%M:%S') BETWEEN '{s_str}' AND '{e_str}'"
        except Exception as e:
            logger.error(f"æ—¶åŒºè½¬æ¢å¤±è´¥: {e}. å›é€€åˆ°ç®€å•æ—¥æœŸåŒ¹é…ã€‚")
            return f"STR_TO_DATE({col_name}, '%d/%m/%Y') = STR_TO_DATE('{date_filter_utc}', '%Y-%m-%d')"

    def get_id_boundaries(self, table_name, date_filter):
        """è·å–æŒ‡å®šæ—¥æœŸ nGen æ•°æ®çš„ ID èŒƒå›´ (Min/Max ID)ã€‚

        Args:
            table_name: é…ç½®ä¸­çš„è¡¨å key (å¦‚ cnt_cycles)
            date_filter: æ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD)

        Returns:
            tuple: (min_id, max_id) æˆ– (None, None)
        """
        logger.info(f"ğŸ” [LogicRunner] è·å– ID è¾¹ç•Œ: {table_name}, æ—¥æœŸ: {date_filter}")

        # 1. åŠ è½½é…ç½®
        try:
            module = importlib.import_module(f"rules.kpi.{table_name}")
        except ImportError:
            logger.error(f"è§„åˆ™æ–‡ä»¶ rules/kpi/{table_name}.py æœªæ‰¾åˆ°")
            return None, None

        config_module = getattr(module, 'CONFIG', {"need_reference": False})
        config_center = get_table_config(table_name)
        config = {**config_module, **config_center}

        if not config.get("need_reference") or config.get("reference_source") != 'ngen':
            logger.info("é nGen å‚è€ƒæ¨¡å¼ï¼Œè·³è¿‡ ID è¾¹ç•ŒæŸ¥è¯¢")
            return None, None

        ref_table = config.get("reference_table", "ngen")
        # é»˜è®¤ ID åˆ—ä¸º idï¼Œå¯é…ç½®è¦†ç›–
        id_col = config.get("reference_id_col", "id") 
        
        # æ„é€  SQL
        # ä¿®æ­£: ä½¿ç”¨æ—¶åŒºè½¬æ¢åçš„æ—¶é—´èŒƒå›´ï¼Œè€Œéç›´æ¥åŒ¹é…æ—¥æœŸå­—ç¬¦ä¸²
        where_clause = self._get_local_time_range_sql(date_filter, "On_Chasis_Datetime")
        
        sql = f"""
            SELECT MIN({id_col}), MAX({id_col})
            FROM hutchisonports.{ref_table}
            WHERE {where_clause}
            AND Tractor_No LIKE 'AT%'
        """
        
        try:
            df = self.ds_ngen.get_pandas_df(sql)
            if not df.empty and df.iloc[0, 0] is not None:
                min_id = int(df.iloc[0, 0])
                max_id = int(df.iloc[0, 1])
                logger.info(f"âœ… ID èŒƒå›´è·å–æˆåŠŸ: {min_id} - {max_id}")
                return min_id, max_id
            else:
                logger.warning(f"âš ï¸ æœªæŸ¥è¯¢åˆ° ID èŒƒå›´ (å¯èƒ½è¯¥æ—¥æœŸæ— æ•°æ®)")
                return None, None
        except Exception as e:
            logger.error(f"âŒ è·å– ID è¾¹ç•Œå¤±è´¥: {e}")
            return None, None

    def run_checks(self, table_name, date_filter, id_range=None):
        """Run data quality checks for a specific table.

        Args:
            table_name: Target table name under kpi_data_db.
            date_filter: Date string used for partition filtering (YYYY-MM-DD).
            id_range: Optional tuple (start_id, end_id) for sharding.

        Returns:
            dict: Aggregated result including status, violation_count, details, and report_text.
        """
        range_info = f" [ID Range: {id_range}]" if id_range else ""
        logger.info(f"ğŸš€ [LogicRunner V2] å¼€å§‹å¤„ç†è¡¨: {table_name}, æ—¥æœŸ: {date_filter}{range_info}")

        # 1. åŠ¨æ€åŠ è½½è§„åˆ™æ¨¡å—
        try:
            module = importlib.import_module(f"rules.kpi.{table_name}")
        except ImportError:
            return {"status": "ERROR", "msg": f"Rule file rules/kpi/{table_name}.py not found", "report_text": "è§„åˆ™æ–‡ä»¶ç¼ºå¤±"}

        # è¯»å–é…ç½® (è§„åˆ™å†…é…ç½® + ä¸­å¤®é…ç½®åˆå¹¶)
        config_module = getattr(module, 'CONFIG', {"need_reference": False})
        config_center = get_table_config(table_name)
        # ä¸­å¤®é…ç½®ä¼˜å…ˆè¦†ç›–
        config = {**config_module, **config_center}
        
        df_self = None
        df_ref = None

        # =========================================================
        # åœºæ™¯ A: éœ€è¦å‚è€ƒæ•°æ® (è·¨åº“)
        # =========================================================
        if config.get("need_reference") and config.get("reference_source") == 'ngen':
            ref_table_name = config.get("reference_table", "ngen")
            target_key = config.get("join_key_target") # Tractor_Cycle_Id
            source_key = config.get("join_key_source") # cycleId
            id_col = config.get("reference_id_col", "id")

            # --- æ‹‰å– nGen æ•°æ® (SQL ä¸‹æ¨) ---
            # è¿™é‡Œçš„æ—¥æœŸæ ¼å¼å¿…é¡»åŒ¹é… nGen æ•°æ®åº“çš„å®é™…å­˜å‚¨æ ¼å¼
            # å‡è®¾æ•°æ®åº“é‡Œå­˜çš„æ˜¯ '11/12/2024...' è¿™ç§å­—ç¬¦ä¸²
            
            # åŠ¨æ€æ„å»º WHERE å­å¥
            if id_range:
                start_id, end_id = id_range
                # ç­–ç•¥: ç‰©ç† ID åˆ†ç‰‡æ¨¡å¼ (é’ˆå¯¹æ–°æ•°æ®)
                # ç›´æ¥ä½¿ç”¨ ID èŒƒå›´åœˆå®šä¸€æ‰¹æ•°æ®ï¼Œä¸å åŠ æ—¥æœŸè¿‡æ»¤ã€‚
                # ç†ç”±: nGen æ•°æ®çš„ ID æ˜¯ç‰©ç†è¿ç»­çš„å¯¼å…¥æ‰¹æ¬¡ï¼Œä½†ä¸šåŠ¡æ—¥æœŸå¯èƒ½æ˜¯ä¹±åºçš„ã€‚
                # ä½¿ç”¨ ID èŒƒå›´å¯ä»¥ä¿è¯è¯¥æ‰¹æ¬¡æ•°æ®è¢«å®Œæ•´æ£€æµ‹ï¼Œä¸æ¼æ‰ä»»ä½•ä¸€æ¡ã€‚
                where_clause = f"{id_col} BETWEEN {start_id} AND {end_id}"
                logger.info(f"ä½¿ç”¨ ID åˆ†ç‰‡æ¨¡å¼: {where_clause}")
            else:
                # ç­–ç•¥: ä¸šåŠ¡æ—¥æœŸæ¨¡å¼ (é’ˆå¯¹æ—§æ•°æ®æ›´æ–°)
                # ä¿®æ­£: è€ƒè™‘åˆ°æ—¶åŒºå·®å¼‚ï¼Œå°† UTC Date è½¬æ¢ä¸º Local Time Range
                where_clause = self._get_local_time_range_sql(date_filter, "On_Chasis_Datetime")
                logger.info(f"ä½¿ç”¨æ—¥æœŸè¿‡æ»¤æ¨¡å¼ (TZ Adjusted): {where_clause}")

            sql_ngen = f"""
                SELECT {target_key}, On_Chasis_Datetime, Off_Chasis_Datetime
                FROM hutchisonports.{ref_table_name}
                WHERE {where_clause}
                AND Tractor_No LIKE 'AT%'
            """
            logger.info("æ­£åœ¨æ‹‰å– nGen æ•°æ®...")
            
            try:
                df_ref_pd = self.ds_ngen.get_pandas_df(sql_ngen)
                df_ref_raw = pl.from_pandas(df_ref_pd)
                
                # ---nGen æ•°æ®æ¸…æ´— ---
                if df_ref_raw.height > 0:
                    site_tz = os.getenv("SITE_TIMEZONE", "UTC")
                    
                    df_ref_clean = df_ref_raw.with_columns(
                        pl.col(target_key).cast(pl.Int64),
                        
                        # æ¸…æ´— nGen æ—¶é—´: æŒ‡å®šæ ¼å¼ -> è½¬æ—¶åŒº -> è½¬UTC
                        pl.col("On_Chasis_Datetime")
                        .str.to_datetime(format="%d/%m/%Y %H:%M:%S", strict=False)
                        .dt.replace_time_zone(site_tz, ambiguous="earliest").dt.convert_time_zone("UTC"),
                        
                        pl.col("Off_Chasis_Datetime")
                        .str.to_datetime(format="%d/%m/%Y %H:%M:%S", strict=False)
                        .dt.replace_time_zone(site_tz, ambiguous="earliest").dt.convert_time_zone("UTC")
                    )
                    
                    # èšåˆå»é‡ (å–æœ€æ—©å¼€å§‹ï¼Œæœ€æ™šç»“æŸ)
                    df_ref = df_ref_clean.group_by(target_key).agg([
                        pl.col("On_Chasis_Datetime").min(),
                        pl.col("Off_Chasis_Datetime").max(),
                    ])
                    logger.info(f"nGen æ•°æ®å‡†å¤‡å®Œæ¯•: {df_ref.height} æ¡")
                else:
                    df_ref = pl.DataFrame() # ç©ºè¡¨
                    
            except Exception as e:
                err_msg = f"nGen æ•°æ®è¯»å–/æ¸…æ´—å¤±è´¥: {str(e)}"
                logger.error(err_msg)
                return {"status": "ERROR", "msg": err_msg, "report_text": err_msg}

            # --- A4. æ‹‰å– Cactus æ•°æ® (æ ¹æ® nGen ID è¿‡æ»¤) ---
            if df_ref is not None and df_ref.height > 0:
                ids = df_ref[target_key].unique().to_list()
                ids_str = ",".join([f"'{i}'" for i in ids])
                
                # æ ¸å¿ƒä¼˜åŒ–: Dynamic Precise Window (åŠ¨æ€ç²¾å‡†çª—å£)
                min_time = df_ref["On_Chasis_Datetime"].min()
                max_time = df_ref["Off_Chasis_Datetime"].max()
                
                # è¯»å–ç¼“å†²é…ç½®ï¼Œé»˜è®¤ 3 å°æ—¶
                buffer_hours = config.get("time_window_buffer_hours", 3)
                buffer = timedelta(hours=buffer_hours)
                
                # è½¬æ¢ä¸º SQL å‹å¥½çš„å­—ç¬¦ä¸²æ ¼å¼ (UTC)
                time_filter_clause = ""
                if min_time and max_time:
                    window_start = (min_time - buffer).strftime('%Y-%m-%d %H:%M:%S')
                    window_end = (max_time + buffer).strftime('%Y-%m-%d %H:%M:%S')
                    time_filter_clause = f"AND _time_begin BETWEEN '{window_start}' AND '{window_end}'"
                    logger.info(f"â±ï¸ å¯ç”¨åŠ¨æ€ç²¾å‡†çª—å£: {window_start} ~ {window_end}")
                
                sql_kpi = f"SELECT * FROM kpi_data_db.{table_name} WHERE {source_key} IN ({ids_str}) {time_filter_clause}"
                
                logger.info(f"æ­£åœ¨æ‹‰å– Cactus æ•°æ® (è¿‡æ»¤ {len(ids)} ä¸ªID)...")
                df_self = pl.from_pandas(self.ds_kpi.get_pandas_df(sql_kpi))
                
                # Cactus æ•°æ®æ¸…æ´— (æˆªå–å‰19ä½)
                if df_self.height > 0:
                    df_self = df_self.with_columns(
                         pl.col(source_key).cast(pl.Int64),
                         pl.col("_time_end").cast(pl.String).str.slice(0, 19).str.to_datetime(strict=False).dt.replace_time_zone("UTC"),
                         pl.col("_time_begin").cast(pl.String).str.slice(0, 19).str.to_datetime(strict=False).dt.replace_time_zone("UTC")
                    )

        # =========================================================
        # åœºæ™¯ B: å•è¡¨æ¨¡å¼ (ä¸éœ€è¦å‚è€ƒåº“)
        # =========================================================
        else:
            logger.info("å•è¡¨æ¨¡å¼: ä»…æ‹‰å–è‡ªé‡‡æ•°æ®...")
            # å…¼å®¹ä¸åŒè¡¨çš„æ—¥æœŸå­—æ®µï¼Œé»˜è®¤ _time_beginï¼Œå…è®¸é…ç½®è¦†ç›–
            date_col = config.get("date_filter_column", "_time_begin")
            limit_clause = ""
            if config.get("sql_limit"):
                limit_clause = f" LIMIT {config['sql_limit']}"

            sql_tpl = config.get("select_sql_template")
            if sql_tpl:
                sql_kpi = sql_tpl.format(
                    table_name=table_name,
                    date_filter=date_filter,
                    date_col=date_col,
                    limit_clause=limit_clause
                )
            else:
                sql_kpi = f"SELECT * FROM kpi_data_db.{table_name} WHERE DATE({date_col}) = '{date_filter}'{limit_clause}"
            df_self = pl.from_pandas(self.ds_kpi.get_pandas_df(sql_kpi))
            # å¯ä»¥åœ¨è¿™é‡Œè¡¥å……å•è¡¨çš„æ—¶é—´æ¸…æ´—é€»è¾‘...

        # =========================================================
        # 3. è°ƒç”¨è§„åˆ™ & ç”ŸæˆæŠ¥å‘Š
        # =========================================================
        
        # å®¹é”™ï¼šå¦‚æœæ•°æ®æ²¡æ‹‰åˆ°
        if df_self is None or df_self.height == 0:
             msg = f"æœªæ‰¾åˆ° Cactus æ•°æ® (æ—¥æœŸ: {date_filter})"
             return {"status": "SKIPPED", "msg": msg, "report_text": msg}

        # ã€æ ¸å¿ƒã€‘è°ƒç”¨ V2 ç‰ˆæœ¬çš„å…¥å£å‡½æ•°
        report_list = module.get_logic_rules(df_self, df_ref)
        
        # ç»Ÿè®¡ç»“æœ
        failed_count = sum([1 for r in report_list if not r.get('passed', True)])
        final_status = "FAILED" if failed_count > 0 else "SUCCESS"
        
        # æå–æ—¶é—´èŒƒå›´ä¾›æŠ¥å‘Šä½¿ç”¨ (å¦‚æœå­˜åœ¨)
        time_range = "N/A"
        if df_ref is not None and df_ref.height > 0:
             try:
                min_t = df_ref["On_Chasis_Datetime"].min().strftime("%m-%d %H:%M")
                max_t = df_ref["On_Chasis_Datetime"].max().strftime("%m-%d %H:%M")
                time_range = f"{min_t} ~ {max_t}"
             except:
                 pass

        # æå–å¤±è´¥è§„åˆ™è¯¦æƒ…
        failed_rules = []
        for r in report_list:
            if not r.get('passed', True):
                # å°è¯•æå–æ ·æœ¬æ•°æ® (æ ‡å‡†åŒ–å­—æ®µ: missing_samples, failed_samples, outlier_samples)
                samples = []
                for sample_key in ['missing_samples', 'failed_samples', 'outlier_samples']:
                    raw_samples = r.get(sample_key)
                    if raw_samples and isinstance(raw_samples, list):
                        # å¢å¼ºç‰ˆæå–ï¼šä¿ç•™ Key åç§°ï¼Œä¾‹å¦‚ "Tractor_Cycle_Id: 12345"
                        extracted_info = []
                        for s in raw_samples:
                            if isinstance(s, dict) and s:
                                # å°è¯•æå–ç¬¬ä¸€ä¸ªé”®å€¼å¯¹ï¼Œæˆ–è€…æå–æ‰€æœ‰é”®å€¼å¯¹
                                # è¿™é‡Œä¸ºäº†ç®€æ´ï¼Œå–ç¬¬ä¸€ä¸ª Key-Value
                                first_k, first_v = list(s.items())[0]
                                extracted_info.append(f"{first_k}: {first_v}")
                        
                        if extracted_info:
                            samples.extend(extracted_info)
                            break # æ‰¾åˆ°ä¸€ç§æ ·æœ¬æ ¼å¼å°±å¤Ÿäº†

                failed_rules.append({
                    "rule": r.get('type', 'Unknown'),
                    "msg": str(r.get('msg', 'No message'))[:100], # æˆªæ–­è¿‡é•¿ä¿¡æ¯
                    "samples": samples[:50] # å¢åŠ åˆ°50ä¸ªæ ·æœ¬ï¼Œæ»¡è¶³"å®Œæ•´ä¿¡æ¯"éœ€æ±‚
                })

        # ç”ŸæˆæŠ¥å‘Šæ–‡æœ¬ï¼ˆé€šè¿‡åœºæ™¯ä¹Ÿæ‰“å°å…³é”®ç»Ÿè®¡ä¿¡æ¯ï¼‰
        report_str = f"æ£€æµ‹è¡¨: {table_name}\næ—¥æœŸ: {date_filter}\næ—¶é—´èŒƒå›´: {time_range}\nçŠ¶æ€: {final_status}\n\n"
        for r in report_list:
            status_icon = "âœ…" if r.get('passed') else "âŒ"
            report_str += f"{status_icon} [{r.get('type', 'Check')}]\n"

            # è‹¥è§„åˆ™è¿”å›ç»Ÿè®¡ä¿¡æ¯ï¼ˆå‡å€¼/æ ‡å‡†å·®/ä¸Šä¸‹ç•Œï¼‰ï¼Œé€šè¿‡æ—¶ä¹Ÿæ‰“å°
            stats_keys = ["mean", "std_dev", "upper_limit", "lower_limit", "total_samples", "outlier_count", "outlier_ratio"]
            stats_items = {k: r[k] for k in stats_keys if k in r}
            if stats_items:
                report_str += f"   ç»Ÿè®¡: {stats_items}\n"

            if not r.get('passed'):
                report_str += f"   è¯¦æƒ…: {r}\n"  # æ‰“å°å¤±è´¥æ ·æœ¬ç­‰

            report_str += "-" * 20 + "\n"

        return {
            "status": final_status,
            "violation_count": failed_count,
            "details": report_list,
            "report_text": report_str,
            "meta_time_range": time_range,
            "meta_failed_rules": failed_rules
        }