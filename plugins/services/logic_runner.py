import polars as pl
from airflow.providers.mysql.hooks.mysql import MySqlHook
import importlib
import logging
import traceback
import os

logger = logging.getLogger("airflow.task")

class LogicRunner:
    def __init__(self, cactus_conn_id, ngen_conn_id):
        self.hook_kpi = MySqlHook(mysql_conn_id=cactus_conn_id)
        self.hook_ngen = MySqlHook(mysql_conn_id=ngen_conn_id)

    def run_checks(self, table_name, date_filter):
        """
        V2ç‰ˆæ‰§è¡Œå™¨ï¼šåŸºäº CONFIG å­—å…¸é©±åŠ¨æ•°æ®åŠ è½½
        """
        logger.info(f"ğŸš€ [LogicRunner V2] å¼€å§‹å¤„ç†è¡¨: {table_name}, æ—¥æœŸ: {date_filter}")

        # 1. åŠ¨æ€åŠ è½½è§„åˆ™æ¨¡å—
        try:
            module = importlib.import_module(f"rules.kpi.{table_name}")
        except ImportError:
            return {"status": "ERROR", "msg": f"Rule file rules/kpi/{table_name}.py not found", "report_text": "è§„åˆ™æ–‡ä»¶ç¼ºå¤±"}

        # è¯»å–é…ç½® (è¿™å°±æ˜¯ V2 çš„æ ¸å¿ƒ)
        config = getattr(module, 'CONFIG', {"need_reference": False})
        
        df_self = None
        df_ref = None

        # =========================================================
        # åœºæ™¯ A: éœ€è¦ nGen å‚è€ƒæ•°æ® (è·¨åº“)
        # =========================================================
        if config.get("need_reference") and config.get("reference_source") == 'ngen':
            ref_table_name = config.get("reference_table", "ngen")
            target_key = config.get("join_key_target") # Tractor_Cycle_Id
            source_key = config.get("join_key_source") # cycleId

            # --- æ‹‰å– nGen æ•°æ® (SQL ä¸‹æ¨) ---
            # è¿™é‡Œçš„æ—¥æœŸæ ¼å¼å¿…é¡»åŒ¹é… nGen æ•°æ®åº“çš„å®é™…å­˜å‚¨æ ¼å¼
            # å‡è®¾æ•°æ®åº“é‡Œå­˜çš„æ˜¯ '11/12/2024...' è¿™ç§å­—ç¬¦ä¸²
            sql_ngen = f"""
                SELECT {target_key}, On_Chasis_Datetime, Off_Chasis_Datetime
                FROM hutchisonports.{ref_table_name}
                WHERE STR_TO_DATE(On_Chasis_Datetime, '%d/%m/%Y') = STR_TO_DATE('{date_filter}', '%Y-%m-%d')
                AND Tractor_No LIKE 'AT%'
            """
            logger.info("æ­£åœ¨æ‹‰å– nGen æ•°æ®(Filter:AT%)...")
            
            try:
                df_ref_pd = self.hook_ngen.get_pandas_df(sql_ngen)
                df_ref_raw = pl.from_pandas(df_ref_pd)
                
                # ---nGen æ•°æ®æ¸…æ´— ---
                if df_ref_raw.height > 0:
                    site_tz = os.getenv("SITE_TIMEZONE", "UTC")
                    
                    df_ref_clean = df_ref_raw.with_columns(
                        pl.col(target_key).cast(pl.Int64),
                        
                        # æ¸…æ´— nGen æ—¶é—´: æŒ‡å®šæ ¼å¼ -> è½¬æ—¶åŒº -> è½¬UTC
                        pl.col("On_Chasis_Datetime")
                        .str.to_datetime(format="%d/%m/%Y %H:%M:%S", strict=False)
                        .dt.replace_time_zone(site_tz, ambiguous="earliest").dt.convert_time_zone("UTC"),
                        
                        pl.col("Off_Chasis_Datetime")
                        .str.to_datetime(format="%d/%m/%Y %H:%M:%S", strict=False)
                        .dt.replace_time_zone(site_tz, ambiguous="earliest").dt.convert_time_zone("UTC")
                    )
                    
                    # èšåˆå»é‡ (å–æœ€æ—©å¼€å§‹ï¼Œæœ€æ™šç»“æŸ)
                    df_ref = df_ref_clean.group_by(target_key).agg([
                        pl.col("On_Chasis_Datetime").min(),
                        pl.col("Off_Chasis_Datetime").max(),
                    ])
                    logger.info(f"nGen æ•°æ®å‡†å¤‡å®Œæ¯•: {df_ref.height} æ¡")
                else:
                    df_ref = pl.DataFrame() # ç©ºè¡¨
                    
            except Exception as e:
                err_msg = f"nGen æ•°æ®è¯»å–/æ¸…æ´—å¤±è´¥: {str(e)}"
                logger.error(err_msg)
                return {"status": "ERROR", "msg": err_msg, "report_text": err_msg}

            # --- A4. æ‹‰å– Cactus æ•°æ® (æ ¹æ® nGen ID è¿‡æ»¤) ---
            if df_ref is not None and df_ref.height > 0:
                ids = df_ref[target_key].unique().to_list()
                ids_str = ",".join([f"'{i}'" for i in ids])
                
                sql_kpi = f"SELECT * FROM kpi_data_db.{table_name} WHERE {source_key} IN ({ids_str})"
                logger.info(f"æ­£åœ¨æ‹‰å– Cactus æ•°æ® (è¿‡æ»¤ {len(ids)} ä¸ªID)...")
                df_self = pl.from_pandas(self.hook_kpi.get_pandas_df(sql_kpi))
                
                # Cactus æ•°æ®æ¸…æ´— (æˆªå–å‰19ä½)
                if df_self.height > 0:
                    df_self = df_self.with_columns(
                         pl.col(source_key).cast(pl.Int64),
                         pl.col("_time_end").cast(pl.String).str.slice(0, 19).str.to_datetime(strict=False).dt.replace_time_zone("UTC"),
                         pl.col("_time_begin").cast(pl.String).str.slice(0, 19).str.to_datetime(strict=False).dt.replace_time_zone("UTC")
                    )

        # =========================================================
        # åœºæ™¯ B: å•è¡¨æ¨¡å¼ (ä¸éœ€è¦ nGen)
        # =========================================================
        else:
            logger.info("å•è¡¨æ¨¡å¼: ä»…æ‹‰å–è‡ªé‡‡æ•°æ®...")
            # å…¼å®¹ä¸åŒè¡¨çš„æ—¥æœŸå­—æ®µï¼Œé»˜è®¤ _time_beginï¼Œå…è®¸åœ¨ CONFIG ä¸­é€šè¿‡ date_filter_column è¦†ç›–
            date_col = config.get("date_filter_column", "_time_begin")
            sql_kpi = f"SELECT * FROM kpi_data_db.{table_name} WHERE DATE({date_col}) = '{date_filter}'"
            df_self = pl.from_pandas(self.hook_kpi.get_pandas_df(sql_kpi))
            # å¯ä»¥åœ¨è¿™é‡Œè¡¥å……å•è¡¨çš„æ—¶é—´æ¸…æ´—é€»è¾‘...

        # =========================================================
        # 3. è°ƒç”¨è§„åˆ™ & ç”ŸæˆæŠ¥å‘Š
        # =========================================================
        
        # å®¹é”™ï¼šå¦‚æœæ•°æ®æ²¡æ‹‰åˆ°
        if df_self is None or df_self.height == 0:
             msg = f"æœªæ‰¾åˆ° Cactus æ•°æ® (æ—¥æœŸ: {date_filter})"
             return {"status": "SKIPPED", "msg": msg, "report_text": msg}

        # ã€æ ¸å¿ƒã€‘è°ƒç”¨ V2 ç‰ˆæœ¬çš„å…¥å£å‡½æ•°
        report_list = module.get_logic_rules(df_self, df_ref)
        
        # ç»Ÿè®¡ç»“æœ
        failed_count = sum([1 for r in report_list if not r.get('passed', True)])
        final_status = "FAILED" if failed_count > 0 else "SUCCESS"
        
        # ç”ŸæˆæŠ¥å‘Šæ–‡æœ¬ï¼ˆé€šè¿‡åœºæ™¯ä¹Ÿæ‰“å°å…³é”®ç»Ÿè®¡ä¿¡æ¯ï¼‰
        report_str = f"æ£€æµ‹è¡¨: {table_name}\næ—¥æœŸ: {date_filter}\nçŠ¶æ€: {final_status}\n\n"
        for r in report_list:
            status_icon = "âœ…" if r.get('passed') else "âŒ"
            report_str += f"{status_icon} [{r.get('type', 'Check')}]\n"

            # è‹¥è§„åˆ™è¿”å›ç»Ÿè®¡ä¿¡æ¯ï¼ˆå‡å€¼/æ ‡å‡†å·®/ä¸Šä¸‹ç•Œï¼‰ï¼Œé€šè¿‡æ—¶ä¹Ÿæ‰“å°
            stats_keys = ["mean", "std_dev", "upper_limit", "lower_limit", "total_samples", "outlier_count", "outlier_ratio"]
            stats_items = {k: r[k] for k in stats_keys if k in r}
            if stats_items:
                report_str += f"   ç»Ÿè®¡: {stats_items}\n"

            if not r.get('passed'):
                report_str += f"   è¯¦æƒ…: {r}\n"  # æ‰“å°å¤±è´¥æ ·æœ¬ç­‰

            report_str += "-" * 20 + "\n"

        return {
            "status": final_status,
            "violation_count": failed_count,
            "details": report_list,
            "report_text": report_str
        }