from airflow.providers.mysql.hooks.mysql import MySqlHook
import pandera as pa
import pandas as pd
import logging

logger = logging.getLogger("airflow.task")

def run_pandera_validation(conn_id, table_name, schema_obj, custom_where=None, sql_limit=None):
    """
    é€šç”¨æ ¡éªŒå‡½æ•°
    """
    logger.info(f"ğŸš€ å¼€å§‹æ ¡éªŒè¡¨: {table_name}")
    
    hook = MySqlHook(mysql_conn_id=conn_id)
    
    # æ„é€  SQL
    where_clause = f"WHERE {custom_where}" if custom_where else ""
    limit_clause = f"LIMIT {sql_limit}" if sql_limit else ""
    
    # æ‹¼è£…å®Œæ•´ SQL
    sql = f"SELECT * FROM {table_name} {where_clause} {limit_clause}"
    
    logger.info(f"æ‰§è¡Œ SQL: {sql}")
    
    # è¯»å–æ•°æ®
    df = hook.get_pandas_df(sql)
    
    if len(df) == 0:
        logger.info("âš ï¸ æ²¡æœ‰è¯»å–åˆ°æ•°æ®ï¼Œè·³è¿‡æ ¡éªŒã€‚")
        return {"status": "SKIPPED", "error_count": 0, "rows": 0}
        
    logger.info(f"ğŸ“¥ è¯»å–æ•°æ®å®Œæˆï¼Œå…± {len(df)} è¡Œï¼Œå¼€å§‹æ‰§è¡Œè§„åˆ™...")

    try:
        schema_obj.validate(df, lazy=True)
        logger.info(f"âœ… {table_name} æ ¡éªŒé€šè¿‡ï¼")
        return {"status": "SUCCESS", "error_count": 0, "rows": len(df)}

    except pa.errors.SchemaErrors as err:
        failure_cases = err.failure_cases
        error_count = len(failure_cases)
        logger.error(f"âŒ {table_name} æ ¡éªŒå¤±è´¥ï¼å‘ç° {error_count} ä¸ªé—®é¢˜ã€‚")
        
        # ç®€å•æ‰“å°æ‘˜è¦
        logger.error(f"é”™è¯¯æ ·æœ¬:\n{failure_cases.head(5)}")
        
        return {
            "status": "FAILED",
            "error_count": error_count,
            "report": failure_cases.to_json()
        }