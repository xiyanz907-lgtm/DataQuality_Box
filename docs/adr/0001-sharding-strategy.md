# ADR 001: 针对 G 级别数据的分片与并发拉取策略

- **状态**: 已采纳 (Accepted)
- **日期**: 2025-12-10
- **决策人**: Joy Zhou
- **标签**: #性能优化 #Airflow #Polars

## 1. 背景 (Context)
目前的逻辑是按天全量拉取数据。随着 nGen 系统接入，单日数据量达到 G 级别（千万行）。
- **风险 1**: Airflow LocalExecutor 单机内存（Docker 8GB）无法一次性加载全量数据，导致 OOM。
- **风险 2**: 数据库单次查询压力过大，容易超时。

考虑了两种切分维度：
1. **按 Vehicle ID (车号) 切分**：业务逻辑最自然。
2. **按 Primary Key (自增 ID) 切分**：数据库物理存储最自然。

## 2. 决策 (Decision)
决定采用 **“基于物理 ID 的动态分片策略”**，并结合 **“动态时间窗口”** 进行跨库查询。

### 核心逻辑：
1.  **Worker Master 节点**：先查询当日数据的 `MIN(id)` 和 `MAX(id)`。
2.  **切片**：按 `BATCH_SIZE = 50,000` 将 ID 范围切分为多个区间。
3.  **并发**：利用 Airflow `Dynamic Task Mapping` 并发启动多个 Worker。
4.  **查询**：
    - nGen 端：使用 `WHERE id BETWEEN start AND end` 强制走主键索引。
    - Cactus 端：使用 nGen 数据计算出的 `[min_time - 3h, max_time + 3h]` 动态窗口走时间索引。

## 3. 备选方案与否决理由 (Alternatives)

### 方案 A：按车号 (Vehicle ID) 分片
- **做法**：先查出所有车号，每个 Task 查一辆车。
- **否决理由**：nGen 表的 `vehicle_id` 字段无索引。这会导致 N 次并发的全表扫描，直接击穿数据库 I/O。

### 方案 B：Airflow Pool 限制全量并发
- **做法**：不切分，只是限制同时只能跑 1 个任务。
- **否决理由**：虽然保护了数据库，但单任务内存依然会爆；且处理速度太慢，无法满足时效性。

## 4. 后果 (Consequences)

### 正面影响 (Pros)
- **内存安全**：单次处理数据量恒定，不再随业务量增长而崩溃。
- **数据库友好**：查询全部走索引（主键索引 + 时间索引），无全表扫描。
- **速度提升**：可以利用多核 CPU 并行处理。

### 负面影响 (Cons) / 风险
- **单表模式复杂化**：对于需要计算全局统计值（如 3-Sigma）的单表任务，直接分片会导致统计误差。
- **对策**：针对单表模式（如 `cnt_newcycles`），暂不启用分片，维持全量拉取（混合模式）。

