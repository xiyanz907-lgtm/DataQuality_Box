# DAG Factory å®æ–½æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

DAG Factory æ˜¯ä¸€ä¸ªåŠ¨æ€ DAG ç”Ÿæˆç³»ç»Ÿï¼Œé€šè¿‡æ‰«æ `plugins/configs/sources/*.yaml` é…ç½®æ–‡ä»¶è‡ªåŠ¨ç”Ÿæˆå®Œæ•´çš„æ•°æ®æ²»ç† DAGã€‚

### æ ¸å¿ƒç‰¹æ€§

âœ… **é…ç½®é©±åŠ¨**ï¼šé€šè¿‡ YAML å®šä¹‰æ•°æ®æºã€è°ƒåº¦ç­–ç•¥ã€Sensoré…ç½®  
âœ… **ç±»å‹å®‰å…¨**ï¼šä½¿ç”¨ Pydantic è¿›è¡Œä¸¥æ ¼çš„ Schema æ ¡éªŒ  
âœ… **è‡ªåŠ¨å…³è”**ï¼šåŸºäº `target_entity` è‡ªåŠ¨åŠ è½½ Adapter å’Œ Rules  
âœ… **å®Œæ•´æµæ°´çº¿**ï¼šè‡ªåŠ¨ç”Ÿæˆ Sensor â†’ Loader â†’ Adapter â†’ Rules â†’ Aggregator â†’ Dispatcher  
âœ… **å®¹é”™æœºåˆ¶**ï¼šè·³è¿‡é”™è¯¯é…ç½®ï¼Œä¸é˜»å¡å…¶ä»– DAG åŠ è½½  

---

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### 1. æ ¸å¿ƒç»„ä»¶

```
plugins/
â”œâ”€â”€ schemas/
â”‚   â””â”€â”€ source_config_schema.py       # Pydantic Schema å®šä¹‰
â”œâ”€â”€ orchestration/
â”‚   â”œâ”€â”€ dag_factory.py                # DAG Factory æ ¸å¿ƒé€»è¾‘
â”‚   â””â”€â”€ rule_scanner.py               # è§„åˆ™æ‰«æå™¨ï¼ˆå¤ç”¨ï¼‰
â””â”€â”€ configs/
    â”œâ”€â”€ sources/                      # æ•°æ®æºé…ç½®ç›®å½• âœ¨ æ–°å¢
    â”‚   â”œâ”€â”€ daily_cycle_etl.yaml
    â”‚   â”œâ”€â”€ asset_driven_etl.yaml
    â”‚   â””â”€â”€ manual_adhoc_analysis.yaml
    â”œâ”€â”€ adapters/                     # Adapter é…ç½®ï¼ˆå·²æœ‰ï¼‰
    â”‚   â””â”€â”€ cycle_adapter.yaml
    â””â”€â”€ rules/                        # è§„åˆ™é…ç½®ï¼ˆå·²æœ‰ï¼‰
        â”œâ”€â”€ p0_time_check.yaml
        â”œâ”€â”€ p1_twin_lift.yaml
        â””â”€â”€ p2_timeout.yaml

dags/
â””â”€â”€ dynamic_governance_dags.py        # DAG æ³¨å†Œå…¥å£ âœ¨ æ–°å¢
```

### 2. æ•°æ®æµ

```
YAML Config â†’ Pydantic Validation â†’ DAG Factory â†’ DAG Object â†’ Airflow Globals
     â†“                â†“                   â†“              â†“            â†“
  Schema æ ¡éªŒ      ç±»å‹æ£€æŸ¥          Task ç¼–æ’      ä¾èµ–å…³ç³»     Scheduler è¯†åˆ«
```

### 3. è‡ªåŠ¨å…³è”æœºåˆ¶

```yaml
# source YAML
source_meta:
  target_entity: "Cycle"  # å£°æ˜ç›®æ ‡å®ä½“

# ç³»ç»Ÿè‡ªåŠ¨è¡Œä¸ºï¼š
# 1. åŠ è½½ adapters/cycle_adapter.yaml
# 2. æ‰«æ rules/*.yaml ä¸­æ‰€æœ‰ target_entity: "Cycle" çš„è§„åˆ™
# 3. ç”Ÿæˆå®Œæ•´çš„ Task ä¾èµ–é“¾
```

---

## ğŸ“ é…ç½®æ–‡ä»¶è¯¦è§£

### Source YAML Schema

```yaml
# ===== æ•°æ®æºå…ƒä¿¡æ¯ =====
source_meta:
  id: "unique_source_id"              # å¿…å¡«ï¼Œä¼šè½¬æ¢ä¸º DAG ID: gov_{id}
  name: "æ•°æ®æºåç§°"                   # å¿…å¡«
  description: "æè¿°ä¿¡æ¯"              # å¯é€‰
  target_entity: "Cycle"              # å¿…å¡«ï¼Œå†³å®š Adapter å’Œ Rules çš„åŠ è½½
  owner: "box_admin"                  # å¯é€‰ï¼Œè¦†ç›–å…¨å±€ owner
  tags: ["tag1", "tag2"]              # å¯é€‰

# ===== è°ƒåº¦ç­–ç•¥ =====
scheduling:
  trigger_mode: "CRON"                # å¿…å¡«ï¼Œå¯é€‰å€¼: CRON/MANUAL/DATASET
  
  # trigger_mode=CRON æ—¶å¿…å¡«
  cron_expression: "0 2 * * *"
  
  # trigger_mode=DATASET æ—¶å¿…å¡«
  dataset_uri: "mysql://conn_id/table_name"
  
  # å¯é€‰ï¼šå‰ç½® Sensor
  sensor:
    enabled: true                     # æ˜¯å¦å¯ç”¨
    type: "SQL"                       # SQL/FILE/TIME/EXTERNAL_TASK
    timeout: 3600                     # è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    poke_interval: 60                 # è½®è¯¢é—´éš”ï¼ˆç§’ï¼‰
    mode: "reschedule"                # poke/reschedule
    
    # æ ¹æ® type ä¸åŒï¼Œå¡«å†™å¯¹åº”å­—æ®µ
    sql: "SELECT COUNT(*) > 100 FROM table"  # type=SQL
    conn_id: "mysql_conn"                    # type=SQL
    
    path: "/data/flag.txt"                   # type=FILE
    fs_conn_id: "fs_conn"                    # type=FILEï¼ˆå¯é€‰ï¼‰
    
    wait_seconds: 300                        # type=TIME
    
    external_dag_id: "upstream_dag"          # type=EXTERNAL_TASK
    external_task_id: "task_id"              # type=EXTERNAL_TASKï¼ˆå¯é€‰ï¼‰

# ===== æ•°æ®æå–é…ç½® =====
extractions:                          # å¿…å¡«ï¼Œè‡³å°‘1ä¸ª
  - id: "raw_data_1"                  # æå–ä»»åŠ¡å”¯ä¸€æ ‡è¯†
    source_type: "mysql"              # mysql/postgresql/influxdb/s3/minio
    conn_id: "mysql_conn_id"          # Airflow Connection ID
    query: "SELECT * FROM table"      # SQL æŸ¥è¯¢ï¼ˆæ”¯æŒ Jinja2 æ¨¡æ¿ï¼‰
    output_key: "raw_table_1"         # è¾“å‡ºåˆ° Context çš„ key

  - id: "raw_data_2"
    source_type: "mysql"
    conn_id: "mysql_conn_id"
    table: "table_name"               # æˆ–ç›´æ¥æŒ‡å®šè¡¨å
    output_key: "raw_table_2"

# ===== å¯é€‰ï¼šè¦†ç›–å…¨å±€ default_args =====
default_args:
  owner: "custom_owner"               # è¦†ç›– source_meta.owner
  email: ["team@example.com"]
  email_on_failure: true
  email_on_retry: false
  retries: 3
  retry_delay_minutes: 10
```

### Sensor ç±»å‹è¯¦è§£

| Type | ç”¨é€” | å¿…å¡«å‚æ•° | å¯é€‰å‚æ•° |
|------|------|---------|---------|
| **SQL** | æ£€æŸ¥æ•°æ®åº“æ¡ä»¶ | `sql`, `conn_id` | `mode` |
| **FILE** | æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§ | `path` | `fs_conn_id`, `mode` |
| **TIME** | ç¡¬ç­‰å¾…ä¸€æ®µæ—¶é—´ | `wait_seconds` | - |
| **EXTERNAL_TASK** | ç­‰å¾…å…¶ä»– DAG å®Œæˆ | `external_dag_id` | `external_task_id`, `mode` |

---

## ğŸš€ ä½¿ç”¨æŒ‡å—

### Step 1: åˆ›å»º Source é…ç½®æ–‡ä»¶

```bash
# åœ¨ plugins/configs/sources/ ä¸‹åˆ›å»ºæ–°çš„ YAML æ–‡ä»¶
cd /opt/airflow/plugins/configs/sources/
vim my_new_source.yaml
```

å‚è€ƒç¤ºä¾‹ï¼š
- `daily_cycle_etl.yaml` - CRON å®šæ—¶è§¦å‘
- `asset_driven_etl.yaml` - DATASET äº‹ä»¶é©±åŠ¨
- `manual_adhoc_analysis.yaml` - MANUAL æ‰‹åŠ¨è§¦å‘

### Step 2: é…ç½® Adapterï¼ˆå¦‚æœæ˜¯æ–°å®ä½“ï¼‰

å¦‚æœä½ çš„ `target_entity` æ˜¯æ–°ç±»å‹ï¼ˆå¦‚ `Vehicle`ï¼‰ï¼Œéœ€è¦åˆ›å»ºå¯¹åº”çš„ Adapterï¼š

```bash
vim /opt/airflow/plugins/configs/adapters/vehicle_adapter.yaml
```

å¦‚æœæ˜¯å·²æœ‰çš„ `Cycle` å®ä½“ï¼Œåˆ™ä¼šè‡ªåŠ¨å¤ç”¨ `cycle_adapter.yaml`ã€‚

### Step 3: é…ç½® Rulesï¼ˆå¯é€‰ï¼‰

åœ¨ `plugins/configs/rules/` ä¸‹åˆ›å»ºè§„åˆ™æ–‡ä»¶ï¼ŒæŒ‡å®š `target_entity`:

```yaml
rule_meta:
  rule_id: "rule_vehicle_speed_check"
  target_entity: "Vehicle"  # åŒ¹é… source çš„ target_entity
  severity: "P0"

filter_expr: "speed > 100"
# ...
```

### Step 4: æ ¡éªŒé…ç½®

```bash
# è¿è¡Œæµ‹è¯•éªŒè¯é…ç½®æ­£ç¡®æ€§
docker exec -it cactus_airflow_container pytest /opt/airflow/tests/test_dag_factory.py -v
```

### Step 5: é‡å¯ Airflow Scheduler

```bash
docker-compose restart airflow
```

### Step 6: éªŒè¯ DAG ç”Ÿæˆ

åœ¨ Airflow UI ä¸­æŸ¥çœ‹ï¼š
- DAG ID: `gov_{source_meta.id}`
- æ ‡ç­¾: `auto-generated`, `governance`, `{custom_tags}`

---

## ğŸ§ª æµ‹è¯•

### è¿è¡Œå•å…ƒæµ‹è¯•

```bash
# æµ‹è¯• Pydantic Schema æ ¡éªŒ
pytest tests/test_dag_factory.py::TestSourceConfigSchema -v

# æµ‹è¯• DAG Factory ç”Ÿæˆé€»è¾‘
pytest tests/test_dag_factory.py::TestDAGFactory -v

# æµ‹è¯•é›†æˆï¼ˆåŠ è½½ç¤ºä¾‹é…ç½®ï¼‰
pytest tests/test_dag_factory.py::TestIntegrationWithExamples -v
```

### æ‰‹åŠ¨æµ‹è¯•

```python
# åœ¨ Airflow Container ä¸­æ‰§è¡Œ
docker exec -it cactus_airflow_container python

>>> from plugins.orchestration.dag_factory import DAGFactory
>>> factory = DAGFactory()
>>> dags = factory.scan_and_generate_dags()
>>> print(f"Generated {len(dags)} DAGs")
>>> for dag_id, dag in dags.items():
...     print(f"  - {dag_id}: {len(dag.tasks)} tasks")
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. é…ç½®æ–‡ä»¶é”™è¯¯å¤„ç†

- âŒ **é”™è¯¯é…ç½®ä¸ä¼šé˜»å¡å…¶ä»– DAG åŠ è½½**
- ğŸ“‹ é”™è¯¯ä¿¡æ¯ä¼šè®°å½•åˆ° Airflow Log
- ğŸ” åœ¨ Airflow UI çš„ "Import Errors" ä¸­æŸ¥çœ‹è¯¦ç»†é”™è¯¯

### 2. Pydantic æ ¡éªŒè§„åˆ™

```python
# ä»¥ä¸‹é…ç½®ä¼šè¢«æ‹’ç»ï¼š
# 1. trigger_mode=CRON ä½†ç¼ºå°‘ cron_expression
# 2. sensor.type=SQL ä½†ç¼ºå°‘ sql æˆ– conn_id
# 3. extractions ä¸ºç©ºåˆ—è¡¨
# 4. åŒ…å«æœªå®šä¹‰å­—æ®µï¼ˆextra='forbid'ï¼‰
```

### 3. å‘½åè§„èŒƒ

- **DAG ID**: `gov_{source_meta.id}`
- **Task ID**: 
  - Sensor: `data_ready_sensor`
  - Loader: `universal_loader`
  - Adapter: `domain_adapter`
  - Rules: `rule_tasks.{rule_id}`
  - Aggregator: `context_aggregator`
  - Dispatcher: `notification_dispatcher`

### 4. æ€§èƒ½ä¼˜åŒ–å»ºè®®

- ğŸ“‚ **å¤§é‡ YAML æ–‡ä»¶æ—¶**ï¼šæŒ‰ä¸šåŠ¡åŸŸåˆ†ç»„ï¼Œä½¿ç”¨ `tags` è¿‡æ»¤
- â±ï¸ **Sensor é…ç½®**ï¼šä½¿ç”¨ `mode: reschedule` é‡Šæ”¾ Worker Slot
- ğŸ”„ **è§„åˆ™æ•°é‡æ§åˆ¶**ï¼šæ¯ä¸ªå®ä½“å»ºè®®ä¸è¶…è¿‡ 50 ä¸ªè§„åˆ™

### 5. ä¸ç°æœ‰ DAG çš„å…³ç³»

#### æ–¹æ¡ˆ A: å®Œå…¨æ›¿ä»£ï¼ˆæ¨èï¼‰âœ…

```bash
# åˆ é™¤æ—§çš„ governance_main_dag.py
rm /opt/airflow/dags/governance_main_dag.py

# å°† sources.yaml è¿ç§»åˆ° sources/ ç›®å½•
mv /opt/airflow/plugins/configs/sources.yaml \
   /opt/airflow/plugins/configs/sources/legacy_governance.yaml
```

#### æ–¹æ¡ˆ B: å…±å­˜ï¼ˆè¿‡æ¸¡æœŸï¼‰

- ä¿ç•™ `governance_main_dag.py` ç”¨äºæ ¸å¿ƒä¸šåŠ¡
- DAG Factory ç”Ÿæˆçš„ DAG ç”¨äºæ–°å¢æ•°æ®æº

---

## ğŸ”§ æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: DAG æ²¡æœ‰å‡ºç°åœ¨ UI ä¸­

**æ£€æŸ¥æ­¥éª¤**ï¼š
```bash
# 1. æŸ¥çœ‹ Airflow Scheduler æ—¥å¿—
docker logs cactus_airflow_container --tail=100 | grep "dag_factory"

# 2. æ£€æŸ¥ Import Errors
# åœ¨ Airflow UI: Admin -> Import Errors

# 3. æ‰‹åŠ¨è§¦å‘åŠ è½½
docker exec -it cactus_airflow_container python /opt/airflow/dags/dynamic_governance_dags.py
```

### é—®é¢˜ 2: Pydantic æ ¡éªŒå¤±è´¥

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
# ä½¿ç”¨ Python ç›´æ¥æ ¡éªŒ YAML
docker exec -it cactus_airflow_container python

>>> import yaml
>>> from plugins.schemas.source_config_schema import SourceYAMLConfig
>>> with open('/opt/airflow/plugins/configs/sources/my_source.yaml') as f:
...     config = yaml.safe_load(f)
>>> SourceYAMLConfig(**config)  # ä¼šæ˜¾ç¤ºè¯¦ç»†é”™è¯¯ä¿¡æ¯
```

### é—®é¢˜ 3: Adapter æˆ– Rules æœªæ‰¾åˆ°

**æ’æŸ¥**ï¼š
```bash
# æ£€æŸ¥ target_entity æ˜¯å¦åŒ¹é…
grep -r "target_entity" /opt/airflow/plugins/configs/

# åº”è¯¥åœ¨ä»¥ä¸‹æ–‡ä»¶ä¸­ä¸€è‡´ï¼š
# - sources/{source}.yaml: target_entity: "Cycle"
# - adapters/cycle_adapter.yaml: æ–‡ä»¶åä¸ target_entity å°å†™ä¸€è‡´
# - rules/*.yaml: target_entity: "Cycle"
```

---

## ğŸ“Š ç›‘æ§å’Œè¿ç»´

### ç”Ÿæˆçš„ DAG æ•°é‡ç»Ÿè®¡

```sql
-- åœ¨ Airflow Metadata DB ä¸­æŸ¥è¯¢
SELECT 
    COUNT(*) AS total_dags,
    SUM(CASE WHEN dag_id LIKE 'gov_%' THEN 1 ELSE 0 END) AS generated_dags
FROM dag;
```

### é…ç½®æ–‡ä»¶å˜æ›´è·Ÿè¸ª

```bash
# å»ºè®®å°† sources/ ç›®å½•çº³å…¥ç‰ˆæœ¬æ§åˆ¶
git add plugins/configs/sources/
git commit -m "feat: add new data source config"
```

---

## ğŸ“š é™„å½•

### A. å®Œæ•´ç¤ºä¾‹é…ç½®

å‚è§ï¼š
- `plugins/configs/sources/daily_cycle_etl.yaml`
- `plugins/configs/sources/asset_driven_etl.yaml`
- `plugins/configs/sources/manual_adhoc_analysis.yaml`

### B. Pydantic Schema å®Œæ•´å®šä¹‰

å‚è§ï¼š`plugins/schemas/source_config_schema.py`

### C. å…¨å±€é»˜è®¤å‚æ•°

```python
# plugins/orchestration/dag_factory.py
GLOBAL_DEFAULT_ARGS = {
    'owner': 'box_admin',
    'depends_on_past': False,
    'email': ['xiyan.zhou@westwell-lab.com'],
    'email_on_failure': True,
    'email_on_retry': False,
    'retries': 2,
    'retry_delay': timedelta(minutes=5),
    'execution_timeout': timedelta(hours=2),
}
```

ä¿®æ”¹å…¨å±€å‚æ•°ï¼šç¼–è¾‘ `dag_factory.py` ä¸­çš„ `GLOBAL_DEFAULT_ARGS`

---

## ğŸ¯ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

### Phase 1: éªŒè¯æ ¸å¿ƒåŠŸèƒ½ï¼ˆæœ¬æ¬¡å®æ–½ï¼‰
- âœ… åˆ›å»º Pydantic Schema
- âœ… å®ç° DAG Factory
- âœ… åˆ›å»ºç¤ºä¾‹é…ç½®
- âœ… ç¼–å†™å•å…ƒæµ‹è¯•
- â³ **æ‰§è¡Œæµ‹è¯•éªŒè¯** â† å½“å‰æ­¥éª¤

### Phase 2: è¿ç§»ç°æœ‰ DAGï¼ˆæ¨èï¼‰
- å°† `governance_main_dag.py` çš„é…ç½®è¿ç§»åˆ° YAML
- åˆ é™¤ç¡¬ç¼–ç çš„ DAG æ–‡ä»¶
- éªŒè¯åŠŸèƒ½ç­‰ä»·æ€§

### Phase 3: æ‰©å±•åŠŸèƒ½ï¼ˆå¯é€‰ï¼‰
- æ”¯æŒæ›´å¤š Sensor ç±»å‹ï¼ˆHttpSensor, S3KeySensorï¼‰
- æ”¯æŒ DAG çº§åˆ«çš„ SLA é…ç½®
- æ”¯æŒåŠ¨æ€ç”Ÿæˆ TaskGroupï¼ˆå¤šé˜¶æ®µæµæ°´çº¿ï¼‰

---

## ğŸ“ æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·è”ç³»ï¼š
- **æŠ€æœ¯è´Ÿè´£äºº**: box_admin
- **é‚®ä»¶**: xiyan.zhou@westwell-lab.com
- **æ–‡æ¡£**: æœ¬æ–‡ä»¶
