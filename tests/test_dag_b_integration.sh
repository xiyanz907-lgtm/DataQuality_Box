#!/bin/bash
# ============================================================
# DAG B é›†æˆæµ‹è¯•è„šæœ¬
# éªŒè¯ DAG A -> Dataset -> DAG B çš„å®Œæ•´æµç¨‹
# ============================================================

set -e  # é‡åˆ°é”™è¯¯ç«‹å³é€€å‡º

echo "ğŸš€ Starting DAG B Integration Test..."
echo "=================================================="

# ============================================================
# é…ç½®å‚æ•°
# ============================================================
MYSQL_CONTAINER="deploy-mysql-1"
AIRFLOW_CONTAINER="deploy-airflow-1"
MYSQL_USER="root"
MYSQL_PASS="your_password"  # è¯·ä¿®æ”¹ä¸ºå®é™…å¯†ç 
DATABASE="your_database"     # è¯·ä¿®æ”¹ä¸ºå®é™…æ•°æ®åº“å

# ============================================================
# Test 1: æ£€æŸ¥æ•°æ®åº“è¡¨
# ============================================================
echo ""
echo "ğŸ“‹ Test 1: Checking database tables..."

# æ£€æŸ¥é˜Ÿåˆ—è¡¨
docker exec -i $MYSQL_CONTAINER mysql -u$MYSQL_USER -p$MYSQL_PASS $DATABASE <<EOF
SELECT 
    CASE 
        WHEN COUNT(*) = 1 THEN 'âœ… governance_asset_packing_queue exists'
        ELSE 'âŒ governance_asset_packing_queue NOT FOUND'
    END AS status
FROM information_schema.tables
WHERE table_schema = '$DATABASE'
  AND table_name = 'governance_asset_packing_queue';
EOF

# æ£€æŸ¥ meta è¡¨çš„ retry_count å­—æ®µ
docker exec -i $MYSQL_CONTAINER mysql -u$MYSQL_USER -p$MYSQL_PASS $DATABASE <<EOF
SELECT 
    CASE 
        WHEN COUNT(*) = 1 THEN 'âœ… retry_count column exists'
        ELSE 'âŒ retry_count column NOT FOUND'
    END AS status
FROM information_schema.columns
WHERE table_schema = '$DATABASE'
  AND table_name = 'auto_test_case_catalog'
  AND column_name = 'retry_count';
EOF

# ============================================================
# Test 2: æ£€æŸ¥ Airflow DAG
# ============================================================
echo ""
echo "ğŸ“‹ Test 2: Checking Airflow DAGs..."

# æ£€æŸ¥ DAG A
docker exec $AIRFLOW_CONTAINER airflow dags list | grep -q "governance_main_dag" && \
    echo "âœ… DAG A (governance_main_dag) found" || \
    echo "âŒ DAG A NOT FOUND"

# æ£€æŸ¥ DAG B
docker exec $AIRFLOW_CONTAINER airflow dags list | grep -q "asset_packing_dag" && \
    echo "âœ… DAG B (asset_packing_dag) found" || \
    echo "âŒ DAG B NOT FOUND"

# ============================================================
# Test 3: æ£€æŸ¥ Dataset
# ============================================================
echo ""
echo "ğŸ“‹ Test 3: Checking Airflow Dataset..."

docker exec $AIRFLOW_CONTAINER airflow datasets list | grep -q "governance_asset_packing_queue" && \
    echo "âœ… Dataset (GOVERNANCE_ASSET_DATASET) found" || \
    echo "âŒ Dataset NOT FOUND"

# ============================================================
# Test 4: æ£€æŸ¥æ‰“åŒ…æœåŠ¡è¿é€šæ€§
# ============================================================
echo ""
echo "ğŸ“‹ Test 4: Testing packing service connectivity..."

curl -s -X GET "https://mock.apipost.net/mock/34a21a/api/launcher/querySyncCacheResult?key=test" \
    -H "Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6MSwidXNlcm5hbWUiOiJ3YW5nZGVmYSIsImV4cCI6MTc2MjUwODE5Nywic3ViIjoiQUNDRVNTIn0.W0b7YmmokSPw1GYb1hQb2AxdHjtKFPsIDaQeUOxPg2w" \
    > /dev/null && \
    echo "âœ… Packing service reachable" || \
    echo "âŒ Packing service UNREACHABLE"

# ============================================================
# Test 5: æ’å…¥æµ‹è¯•æ•°æ®åˆ°é˜Ÿåˆ—
# ============================================================
echo ""
echo "ğŸ“‹ Test 5: Inserting test data..."

docker exec -i $MYSQL_CONTAINER mysql -u$MYSQL_USER -p$MYSQL_PASS $DATABASE <<EOF
INSERT INTO governance_asset_packing_queue 
(batch_id, asset_id, rule_id, vehicle_id, start_time, end_time, base_path, status)
VALUES 
('TEST_BATCH_$(date +%Y%m%d_%H%M%S)', 
 'TEST_ASSET_001', 
 'rule_p1_twin_lift', 
 'V001', 
 NOW(), 
 NOW() + INTERVAL 2 HOUR, 
 '/data/assets/test/', 
 'PENDING')
ON DUPLICATE KEY UPDATE updated_at = NOW();

SELECT 'âœ… Test data inserted' AS status;
EOF

# ============================================================
# Test 6: æ‰‹åŠ¨è§¦å‘ DAG B
# ============================================================
echo ""
echo "ğŸ“‹ Test 6: Manually triggering DAG B..."

docker exec $AIRFLOW_CONTAINER airflow dags trigger asset_packing_dag && \
    echo "âœ… DAG B triggered successfully" || \
    echo "âŒ Failed to trigger DAG B"

# ============================================================
# Test 7: ç­‰å¾… 10 ç§’åæ£€æŸ¥é˜Ÿåˆ—çŠ¶æ€
# ============================================================
echo ""
echo "ğŸ“‹ Test 7: Checking queue status after 10 seconds..."
sleep 10

docker exec -i $MYSQL_CONTAINER mysql -u$MYSQL_USER -p$MYSQL_PASS $DATABASE <<EOF
SELECT 
    asset_id,
    status,
    retry_count,
    error_message,
    updated_at
FROM governance_asset_packing_queue
WHERE asset_id = 'TEST_ASSET_001'
ORDER BY updated_at DESC
LIMIT 1;
EOF

# ============================================================
# Test 8: æ¸…ç†æµ‹è¯•æ•°æ®
# ============================================================
echo ""
echo "ğŸ“‹ Test 8: Cleaning up test data..."

docker exec -i $MYSQL_CONTAINER mysql -u$MYSQL_USER -p$MYSQL_PASS $DATABASE <<EOF
DELETE FROM governance_asset_packing_queue
WHERE asset_id = 'TEST_ASSET_001';

SELECT 'âœ… Test data cleaned' AS status;
EOF

# ============================================================
# å®Œæˆ
# ============================================================
echo ""
echo "=================================================="
echo "âœ… Integration test completed!"
echo ""
echo "ğŸ“ Next Steps:"
echo "  1. Check Airflow UI for DAG B run status"
echo "  2. Review logs: docker logs deploy-airflow-1 | tail -100"
echo "  3. If all tests pass, proceed with production deployment"
echo ""
